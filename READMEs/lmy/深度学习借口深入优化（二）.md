#深度学习借口深入优化（二）

[TOC]

##背景

之前的工作中，我们已经完成了一定程度的并行化和优化，并提到了接下来进一步优化的目标。那之后，我又发掘出了新的优化点，即实现识别工作和图片处理工作的流水进行。

## 目标简述

为了实现这样的流水，我们需要利用我们已有的并行框架进行重构，让图片处理线程在工作时，识别线程同时在工作。为了实现这个功能，我们对图片识别这个过程进行了如下定义：

- 服务器从终端设备处获得图片后，不会立刻进行处理识别，而是等待一段时间，攒够一定数量后提交给模块进行处理
- 图片处理的过程和图片获取的过程是同步的，即函数在处理结束前不会返回
- 图片完成处理之后，将与相关信息一起提交给识别线程，识别线程开始异步工作，完成识别，将结果放入指定位置
- 当需要结果的时候，主线程会等待识别线程工作完成，并把结果取出，用于后续工作

## 链式缓冲区的实现

为了提高效率，图片识别是异步工作的，这就需要我们采用异步的方式处理图像，这就需要将处理后的图片进行缓冲，这里我们想到的最直接的方式就是使用链表——把图片（内存中的）和相关的信息放入链表节点，图片处理线程就根据节点内的信息处理图片保存结果，完成后将结果存入结果缓冲区

为了实现这些，我们首先需要节点的定义。节点应该包含：

- 处理后图片存放的位置
- 这个缓冲区中有多少图片
- 结果存到哪里
- 识别相关参数

有了这些定义，我们就可以去定义节点的创建和回收函数了

除此之外，我们还应该控制缓冲区的大小，如果缓冲区满了，我们应该采取相关措施。在高并发的条件下，我们认为信号量是控制缓冲区大小的不错选择，信号量既可以阻塞等待，也可以异步等待，为我们后期的实现提供了灵活性

综上所述，有以下定义：

```c

typedef struct __linked_buffer {
	struct __linked_buffer*	next;			//下一个batch
	image*					batch_pic;		//本batch的转换结果（图片统一free）
	int**					res_buffer;		//结果缓存
	float*					batch_pic_data; //为了方便资源回收&引用
	float					thresh;			//每个batch的thresh，虽然不认为会变化
	int						batch_size;		//下一个batch的大小
}linked_buffer_t;

/**
 * @brief list_head
 * 链表头指针，我不打算用什么空头
 */
linked_buffer_t* buffer_head;
void buffer_init();
void buffer_finalize();
linked_buffer_t* create_buffer(int buffer_size, float thresh);
void free_buffer(linked_buffer_t* rubbish);

#define MAX_BUFFER_SIZE 3
static sem_t size_sig;
/**
 * @brief create_buffer
 * 创建一个缓冲区，顺便把空间也给他申请了吧
 * @param buffer_size 当前的batch_size
 * @param buffered_data 需要转换的图片，在这里就申请好空间，并在这里释放
 * @return
 */
linked_buffer_t* create_buffer(int buffer_size, float thresh)
{
	sem_wait(&size_sig);
	//为image结构申请空间
	image* sized_pics = calloc(buffer_size, sizeof(image));
	float* cont_data_field = calloc(batch_size*IN_H*IN_W*3, sizeof(float));
	for(int i = 0; i < buffer_size; i++)
	{
		sized_pics[i].data = cont_data_field + i*3*NET_SIZE*NET_SIZE;
		sized_pics[i].w = NET_SIZE;
		sized_pics[i].h = NET_SIZE;
		sized_pics[i].c = 3;
	}
	//申请新节点并赋值
	linked_buffer_t* ret = malloc(sizeof(linked_buffer_t));
	ret->next = NULL;
	ret->batch_size = buffer_size;
	ret->thresh = thresh;
	ret->batch_pic = sized_pics;
	ret->batch_pic_data = cont_data_field;

	if(buffer_head == NULL) buffer_head = ret;
	else
	{
		buffer_head->next = ret;
		buffer_head = ret;
	}
	return ret;
}

/**
 * @brief free_buffer
 * 按照上面释放掉申请的所有资源
 * @param rubbish
 */
void free_buffer(linked_buffer_t* rubbish)
{
	free(rubbish->batch_pic_data);
	free(rubbish->batch_pic);
	free(rubbish);
	sem_post(&size_sig);
}

void buffer_init()
{
	sem_init(&size_sig, 0, MAX_BUFFER_SIZE);
}

void buffer_finalize()
{
	sem_destroy(&size_sig);
}
```

## 线程之间协作的实现

主线程和处理线程之间是同步的，但是和识别线程之间是异步的，所以展示出来的接口应该是这样的：

- 输入图片
- 获取结果

因此，我们之前定义好的Python模块接口也需要重新定义

```c
/*******************************************************
 *
 *radical version
 * pipelining batching process to acquire better paralellism
 *
 *******************************************************/

#include "pydarknet.h"
#include <Python.h>
/**
 * @brief pydarknet_detect
 * python 直接调用的函数，现在做一个过渡，真正的实现不要和Python接口这种东西混在一起
 * @param self
 * @param args
 * @return
 */
static PyObject* pydarknet_feed_detector(PyObject* self, PyObject* args)
{
	float 		thresh;
	PyObject* 	parr;

	PyArg_ParseTuple(args, "fO",&thresh, &parr);

	PyArrayObject *ndarr = (PyArrayObject* ) parr;	//获得对象指针
	batch_size = ndarr->dimensions[0];
	if(!batch_size) Py_RETURN_NONE;

	//把核心逻辑放到别的文件里吧
	do_detection(ndarr->data, thresh);

	batch_size = 0; //最后记得归0
	Py_RETURN_NONE;
}
/**
 * @brief 原来的改的build_pyarr
 * 单独写出来，反正就是为了把int类型转换成一个可以返回的python对象
 * @param coordinates 表示边界的四维数组
 * @return 创建好的可以直接返回的Python对象
 */
static PyObject* pydarknet_pull_results(PyObject* self, PyObject* args)
{
	npy_intp* dims = calloc(2,sizeof(npy_intp));
	dims[0] = total_size;
	dims[1] = 4;

	PyObject* ret = PyArray_SimpleNewFromData(2, dims, NPY_INT, g_res_store);
	Py_INCREF(ret);
	return ret;
}

/**
 * @brief pydarknet_init_detector
 * 完成头文件中关键组件的初始化，同时调用不同实现的初始化函数
 *  datacfg	data文件
 *  cfgfile	cfg文件
 *  weightfile	权值文件
 */
static PyObject* pydarknet_init_detector(PyObject* self, PyObject* args)
{
	char *datacfg, *cfgfile, *weightfile;
	//这样的话多一个参数
	PyArg_ParseTuple(args, "sssi", &datacfg, &cfgfile, &weightfile, &total_size);
	//---------------------------------------------------------------------
	printf("data: %s\ncfg: %s\nweights: %s\n",datacfg, cfgfile, weightfile);
	//---------------------------------------------------------------------

	srand(2222222);
	__init();	//根据功能不同调用不同的

	list *options = read_data_cfg(datacfg);
	char *name_list = option_find_str(options, "names", "data/names.list");
	names = get_labels(name_list);
	net = load_network(cfgfile, weightfile, 0);
	set_batch_network(net, 1);
	Py_RETURN_NONE;//用这个维持Python解释器环境的正常
}

/**
 * @brief pydarknet_finalize_detector
 * 当工作结束后回收资源用，并不是所有实现都用的着
 * @param self
 * @param args
 * @return
 */
static PyObject* pydarknet_finalize_detector( PyObject* self, PyObject* args )
{
	__finalize();
	Py_RETURN_NONE;
}

static PyMethodDef meth_list[] =
{
	{"feed_detector", pydarknet_feed_detector, METH_VARARGS},
	{"pull_result", pydarknet_pull_results, METH_NOARGS},
	{"init_detector", pydarknet_init_detector, METH_VARARGS},
	{"finalize_detector", pydarknet_finalize_detector, METH_NOARGS}, 
	{NULL, NULL, 0, NULL}
};

void initpydarknet()
{
	Py_InitModule("pydarknet", meth_list);
	_import_array();
}

```

然后就是真正实现，首先是全局变量的定义

```c
//转换线程的参数块
typedef struct{
	char*		src;
	float*		dest;
	int			tid;
	int*		check_point;	//用于线程观测同伴工作进度
	sem_t		next_batch;	//这个也改名，由以循环为控制单位到以批为控制单位,中间不停，最慢的线程处理完一张图片v(det_worker.pic_avail)
	pthread_t	tcb;
} conv_t;

//识别线程的描述块
typedef struct{
	linked_buffer_t*		current_job;	//图片，batch大小都在这里
	sem_t				pic_avail;		//这个代替原来的conv_done
	int					res_index;		//该存第几个结果
	pthread_t			tcb;
} det_t;

static conv_t 				pic_workers[CONV_THS];
static det_t				det_worker;

static pthread_barrier_t 	conv_barrier;	//线程之间同步使用，为什么同步？释放check_point

static sem_t				conv_idle;		//同样是处理完成信号，不过这个是给主线程看的
static sem_t				det_sig;		//完成与主线程的同步，开始是det等，结束时主线程等

static int					detect_num;
```

下面是函数的具体实现

```c
static void* thread_detect(void* args)
{
	det_t*	task = (det_t*) args;
	linked_buffer_t* job;
	float	thresh;
	image*	batch_pics;
	int		b_size;

	sem_wait(&det_sig);	//等主线程准备好数据（串好链表）
	while(1)
	{
		int batch_index;
		//printf("281:stuck here?\n");
		job = task->current_job;
		thresh = job->thresh;
		if(thresh == 0)
		{
			sem_post(&det_sig);
			return NULL;
		}
		batch_pics = job->batch_pic;
		b_size = job->batch_size;
		for(batch_index = 0; batch_index < b_size; batch_index++)
		{
			sem_wait(&task->pic_avail);
			test_detector(batch_pics + batch_index, thresh, g_res_store + 4*task->res_index++);
		}
		while(job->next == NULL)
		{//如果说这样可以节约时间片，那么这样是不错的选择
			pthread_yield();
		}
		task->current_job = job->next;
		free_buffer(job);
	}
	return NULL;
}

/**
 * @brief feed_pipeline
 * 向转换线程提供下一个batch，转换线程很快，所以和主线程同步就可以了
 * @param data_field
 * @param next_batch_info
 * @param thresh
 */
static inline void feed_pipeline(char* data_field, linked_buffer_t* next_batch_info)
{
	int i;
	int* check_points = calloc(batch_size, sizeof(int));
	float* pic_data = next_batch_info->batch_pic_data;
	for(i = 0; i < CONV_THS; i++)
	{
		pic_workers[i].src = data_field;		//告诉所有线程第一张图片缓冲区的位置，剩下的自己找去
		pic_workers[i].dest = pic_data;			//转换结果同理
		pic_workers[i].check_point = check_points;	//互相确认进度用的检查点
	}
	gtimer = what_time_is_it_now();
	for(i = 0; i < CONV_THS; i++)
		sem_post(&pic_workers[i].next_batch);
	//---------------------------
	//printf("exiting give_pic...\n");
	//---------------------------
}

int** do_detection(char* data, float thresh)
{
	linked_buffer_t* new_batch = create_buffer(batch_size, thresh);//可能会阻塞！！
	if(detect_num == -1)
	{//还没开始工作，current_job域还是空的，由于这个分支只会执行一次
		det_worker.current_job = new_batch;
		sem_post(&det_sig);
		detect_num = 0;
	}
	detect_num += batch_size;
	feed_pipeline(data, new_batch);
	//printf("353:stuck here?\n");
	if(detect_num == total_size)
	{
		create_buffer(1,0);
		sem_wait(&det_sig);
	}
	sem_wait(&conv_idle);	//策略改变——进来的时候断言转换线程空闲，等到转换完成后退出
	return NULL;
}

void __init()
{
	int i;
	for(i = 0; i < CONV_THS ;i++)
	{
		pic_workers[i].tid = i;
		sem_init(&pic_workers[i].next_batch, 0, 0);
		pthread_create(&pic_workers[i].tcb, NULL, thread_conv_pic, &pic_workers[i]);
	}
	sem_init(&det_worker.pic_avail, 0, 0);
	detect_num = -1;
	pthread_create(&det_worker.tcb, NULL, thread_detect, &det_worker);
	
	//初始化两个全局信号
	sem_init(&conv_idle, 0, 0);
	sem_init(&det_sig, 0, 0);
	
	//初始化路障
	pthread_barrier_init(&conv_barrier, NULL, CONV_THS);

	buffer_head = NULL;
	g_res_store = calloc(total_size*4, sizeof(int));
	buffer_init();
}

void __finalize( void )
{
	int i;
	for(i = 0; i < CONV_THS; i++)
	{
		pic_workers[i].src = -1;
		sem_post(&pic_workers[i].next_batch);
	}

	//printf("threads finalized\n");
	for(i = 0; i < CONV_THS; i++)
		sem_destroy(&pic_workers[i].next_batch);
	//printf("sems finalized\n");
	sem_destroy(&conv_idle);
	sem_destroy(&det_sig);
	buffer_finalize();
}
```

执行真正功能的函数`test_detector`和`thread_conv_pic`前面已经提过，这里不再赘述

##小结

最终的效果还是不错的，最关键的是，这样以来就给线程的数量松绑了，如果系统并发度真的要求高，那么图片处理线程一个就够，能够和识别线程速度匹配。

至此我们的神经网络人脸检测模块实现完毕，接下里就是利用它提供的结果完成其他的功能